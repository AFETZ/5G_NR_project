# Тестовое задание для проекта 1548: 5G NR

## Описание
### Краткое описание сути решения

      В рамках данного задания подготовлена реализация мини конвейра данных для обработки 
    входных данных по обмену пакетами между участниками  движения,  а   также  реализован
    расчет определенных статистических показателей  и  построение графиков,  на основании 
    этих данных

### Требования к проекту по заданию

      В рамках задания требовалось реализовать мини-конвейр сборки данных, который должен
    состоять из следующих частей: парсер логов, подсчет метрик и построение графиков. Все
    это должно иметь возможность запускаться через CLI утилиту
    
      Важными особенностями задания являются то, что скрипты должны быть готовы к обработке
    больших объемов данных, поддерживать streaming-парсинг без загрузки всего файла в память, 
    а также корректно обрабатывать аномалии в данных (в идеале все в многопроцессорном режиме)

### Формат входных данных

      Модель входных данных:
        - ts_us: int (временная метка в микросекундах)
        - event: str ('tx' или 'rx')
        - src: str (источник)
        - dst: str (получатель) 
        - pkt_id: str (идентификатор пакета)
        - app: str (тип приложения)
        - bytes: int (размер пакета в байтах)
        - rssi_dbm: float | None (уровень сигнала)
        - sinr_db: float | None (отношение сигнал/шум)
        - drop_reason: str | None (причина потери пакета)

      Текущие поддерживаемые форматы: CSV, NDJSON

### Собираемые показатели

    - PDR (Packet Delivery Ratio): rx_count / tx_count
    - Latency: средняя, p50, p95, стандартное отклонение
    - Агрегация по временным окнам (по умолчанию 1 секунда)
    - Агрегация по парам src-dst
    - Агрегация по типам приложений

      Текущие поддерживаемые форматы выгрузки: CSV, Parquet

### Собираемые статистики аномалий

    - Дубликаты TX для одного pkt_id
    - Пакеты RX без соответствующих TX
    - Отрицательные задержки
    - Рассинхронизация направления для pkt_id TX -> RX

## Структура проекта

      Проект по заданию имеет следующую структуру:
        5G_NR_test_project:
            .venv
            artifacts: - Директория хранения готовых метрик
                ...
            help_scripts: - Директория с нужными лишними скриптами
                ...
            parsed_files: - Директория хранения распарсшенных данных
                ...
            plots: - Директория хранения подготовленных графиков
                ...
            src:
                5g_nr_test_projetc:
                    configs: - Хранит информацию о структурах и конфигурациях
                        __init__.py
                        interfaces.py
                        models.py
                    main_scripts: - Скрипты, выолняющие основной функционал
                        __init__.py
                        export.py
                        parser_definition.py
                        parsers.py
                        processor.py
                        test_base_parser.py
                    support_scripts: - Вспомогательные скрипты
                        __init__.py
                        work_with_file.py
                    test_input_date: - директория хранения входных данных для обработки
                        ...
                    tests: - 
                        __init__.py
                    visualization:
                        __init__.py
                        plotter.py
                    __init__.py
                    cli.py
                __init__.py
                logs: - Логи работы программы (пока без технических логов и метаданных)
                    nr_metrics.log
            tests: - Директория с тестовыми данными, для показа demo работы
                sample.csv - тестовый csv файл
            __init__.py
            docker-compose.yml
            Dockerfile
            Makefile
            poetry.lock
            pyproject.toml
            README.md

### Детально по структуре скриптов

    configs:
    Изначально создавалась только для хранения возможных  конфигурационных файлов, но было решено  также  туда  отнести
    модели данных и реализацию интерфейса парсеров
        interfaces.py - скрипт в котором реализован интерфейс работы парсеров, через использования абстрактного класса.
                        Так было сделано из-за того, чтобы задать определенную  систему  взаимдействий с парсерами, для
                        удобвства  расширения в  будущем (ну  и на самом   деле испугался  реализовывать через Protocol,
                        так как совсем не знаю как с ним работать правильно)

        models.py - скрипт, который содержит в себе все используемые модели данных, реализованных на pydantic, для 
                    удобвста взаимодействия и самое главное валидации данных (модуль pydantic)

    main_scripts:
        Директория с основными скриптами по работе программы

        test_base_parser.py - скрипт с реализацие базового абстрактного класса (TestParser) для реализации основных 
                              парсеров. Необходим чтобы дополнить изначальный интерфейс парсеров, реализованный в 
                              interfaces.py, дополнительными функциями, которые должны реализовываться в парсерах для 
                              решения проекта

        parsers.py - реализации уже определенных парсеров (NJsonParser, CSVParser и заглушка для Ns3Parser) с логикой
                     обработки определенных источников. Являются наследниками TestParser и реализуют его функционал под
                     конкретные источники данных.

        parser_definition.py - скрипт с реализацией класса определения парсеров, который  используем как  универсальный 
                            инструмент для автоматического выбора парсера, способного считать наш источник. Название 
                            класса ParserFactory

        processor.py - скрипт по реализации класса MetricsCalculator, задача которого подсчет итоговых метрик.

        export.py - скрипт с реализацией класса ComprehensiveMetricsExporter по экспорту данных итоговых метрик в 
                    в удобном для взаимодействия формате. Сохраняет в директорию artifacts

    visualization:
        Директория с скриптом по работе с визуализацией метрик

        plotter.py - скрипт с реализацией класса Plotter, который подготавливает графики по подсчитанным метрикам и 
                     сохраняет их в директорию  plots

    support_script:
        Директория для хранения вспомогательных скриптов

        progress_bar.py - скрипт с классом ProgressBar, необходимый нам для построения удобного вывода статуса загрузки
                          входного файла (Может быть использован и на других итерируемых объектах, этот просто как 
                          пример)

        work_with_file.py - скрипт реализации пары функций для удобного взаимодействия с файлами

    cli.py - скрипт с реализацией CLI с тремя командами взаимодействия: parse, metrics, plot.

### Взаимодействие с CLI

      Взаимодействие с CLI происходит при помощи трех команд: parse, metrics, plot. 

      - "parse" получает путь к файлу источнику, который укажет пользователь и начнет его парсить и валидировать данные 
    на основании модели данных. Все корректные записи запишутся в унифицированные json файл по пути, который укажет 
    пользователь, или если не укажет то по умолчанию внутри parsed_files в корневой директории проекта в формате 
    {название_источника}_{текущая_дата}.json, чтобы его можно было выделить от остальных.
        Аргументы:
            input_file: - путь к файлу источнику
        Опции:
            --output-file: - путь к файлу, куда сохранять обработанные данные

      - "metrics" получает путь от пользователя к файлу распарсшенных данных, после чего начинает их обработку. 
    Реализация немного плохая, так как сначала снова считываю файл при помощи первого подходящего парсера, чтобы 
    создать генератор записей и только потом начинаю обработку и агрегацию статистик. На выходе кладет данные в 
    форматах csv и parquet, либо в директорию, которую указал пользователь, либо по умолчанию в artifacts в корневой
    директории. Внутри artifacts сохраняет в отдельную папку соданную динамически по названию источника и даты 
    обработки, чтобы можно было их различать.
        Аргументы:
            unified_file: - путь к унифицированному файлу
        Опции:
            -o --output-dir: - путь к директории, куда сохранять данные
            -w --window-size: - размер временного окна, которое нужно учитывать при агрегации

      - "plot" получает путь от пользователя путь к директории, где хранятся агрегируемые метрики, после чего строит на 
    основании них графики: CDF задержки, график зависимости задержки от SINR, график PDR по временным окнам
        Аргументы:
            input_file: - путь к файлу источнику
        Опции:
            -o --output-dir: - путь к директории, куда сохранять данные
            --pair: - пары значений src->dst для фильтрации

### Пример использования

      В структуре реализован makefile, с сценариями демо использования, в том числе сборке docker образа. Dockerfile
    есть и лежит в корневой директории проекта.

    Пример:
        make demo-csv - приведет к тестовому прогону скрипта по обработке тестового csv файла, который лежит в
                        директории tests тамже, где и makefile

        make docker-test - собирает docker образ, после чего прогоняет в нем команду parse с тестовым csv файлом
